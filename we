# app.py
import os
from contextlib import asynccontextmanager
from typing import Any, Dict, Optional

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

from services.metadata_service import MetadataService
from services.rag_search_service import RagSearchService

load_dotenv()

AWS_REGION = os.getenv("AWS_REGION", "us-east-1").strip()
FAISS_INDEX_DIR = (os.getenv("FAISS_INDEX_DIR") or "").strip()
CLIENT_GROUP_XLSX_PATH = (os.getenv("CLIENT_GROUP_XLSX_PATH") or "").strip()

XLSX_CLIENT_COL = (os.getenv("XLSX_CLIENT_COL") or "clientName").strip()
XLSX_GROUP_COL = (os.getenv("XLSX_GROUP_COL") or "groupid").strip()

if not FAISS_INDEX_DIR.lower().startswith("s3://"):
    raise RuntimeError(f"FAISS_INDEX_DIR must be s3://bucket/prefix, got: {FAISS_INDEX_DIR!r}")
if not CLIENT_GROUP_XLSX_PATH:
    raise RuntimeError("CLIENT_GROUP_XLSX_PATH is required (s3://... or local path)")

svc = MetadataService(
    client_group_xlsx_path=CLIENT_GROUP_XLSX_PATH,
    faiss_index_dir=FAISS_INDEX_DIR,
    xlsx_client_col=XLSX_CLIENT_COL,
    xlsx_group_col=XLSX_GROUP_COL,
    bedrock_region=AWS_REGION,
)

rag = RagSearchService(
    faiss_index_dir=FAISS_INDEX_DIR,
    bedrock_region=AWS_REGION,
    embedding_model_id=os.getenv("BEDROCK_EMBEDDING_MODEL"),
    default_top_k=int(os.getenv("RAG_TOP_K", "8")),
    default_category=os.getenv("RAG_DEFAULT_CATEGORY", "finance"),
    faiss_cache_dir=os.getenv("FAISS_INDEX_DIR_LOCAL", "/tmp/faiss_indices"),
)


@asynccontextmanager
async def lifespan(app: FastAPI):
    try:
        svc.ensure_loaded()
        print("[INFO] XLSX mapping loaded")
    except Exception as e:
        print(f"[WARN] startup preload failed: {e}")
    yield


app = FastAPI(
    title="Structured Metadata + RAG Retrieval API",
    version="6.0.0",
    lifespan=lifespan,
)


class MetadataLookupRequest(BaseModel):
    client: str
    country: Optional[str] = None  # scope input
    category: str = "finance"
    include_manifest: bool = True
    max_docs_per_manifest: int = 200


class RagSearchRequest(BaseModel):
    query: str
    capid: Optional[str] = None
    group_id: Optional[str] = None

    # scope is mandatory because folder layout is <id>/<scope_dir>/
    country: str  # US / Ultimate Parent / Corporate Family
    category: str = "finance"
    top_k: Optional[int] = None
    include_manifest: bool = False


@app.post("/api/metadata/lookup", response_model=Dict[str, Any], tags=["metadata"])
def metadata_lookup(payload: MetadataLookupRequest):
    client = (payload.client or "").strip()
    if not client:
        raise HTTPException(status_code=400, detail="client is required")

    try:
        res = svc.lookup_structured(
            client=client,
            country=payload.country,
            category=payload.category,
            include_manifest=payload.include_manifest,
            max_docs_per_manifest=payload.max_docs_per_manifest,
        )
        if res.get("error"):
            raise HTTPException(status_code=404, detail=res["error"])
        return res
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"metadata lookup failed: {e}")


@app.post("/api/rag/search", response_model=Dict[str, Any], tags=["rag"])
def rag_search(payload: RagSearchRequest):
    query = (payload.query or "").strip()
    if not query:
        raise HTTPException(status_code=400, detail="query is required")

    scope = (payload.country or "").strip()
    if not scope:
        raise HTTPException(status_code=400, detail="country(scope) is required: US / Ultimate Parent / Corporate Family")

    cap = (payload.capid or "").strip()
    gid = (payload.group_id or "").strip()
    if bool(cap) == bool(gid):
        raise HTTPException(status_code=400, detail="Provide exactly one of capid OR group_id")

    cat = (payload.category or "finance").strip().lower()
    if cat not in {"finance", "legal"}:
        cat = "finance"

    try:
        return rag.retrieve_chunks_structured(
            query=query,
            capid=cap if cap else None,
            group_id=gid if gid else None,
            scope=scope,
            category=cat,
            top_k=payload.top_k,
            include_manifest=payload.include_manifest,
        )
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"rag retrieval failed: {e}")


@app.get("/health", tags=["ops"])
def health():
    return {"status": "ok"}


###


# services/rag_search_service.py
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import boto3
from dotenv import load_dotenv
from langchain_aws import BedrockEmbeddings

try:
    from langchain_community.vectorstores import FAISS  # type: ignore
except Exception:
    from langchain.vectorstores import FAISS  # type: ignore


def _parse_s3_uri(uri: str) -> tuple[str, str]:
    u = urlparse((uri or "").strip())
    bucket = (u.netloc or "").strip()
    key = (u.path or "").lstrip("/")
    if not bucket:
        raise ValueError(f"Invalid S3 URI (missing bucket): {uri}")
    return bucket, key


def _join_key(*parts: str) -> str:
    out = []
    for p in parts:
        p = str(p or "").strip("/")
        if p:
            out.append(p)
    return "/".join(out)


# TEMP TESTING ONLY (DO NOT COMMIT)
S3_AWS_ACCESS_KEY_ID = ""
S3_AWS_SECRET_ACCESS_KEY = ""
S3_AWS_SESSION_TOKEN = ""

BEDROCK_AWS_ACCESS_KEY_ID = ""
BEDROCK_AWS_SECRET_ACCESS_KEY = ""
BEDROCK_AWS_SESSION_TOKEN = ""


def _pick_static_creds_for(profile_env: str) -> tuple[str, str, str]:
    if profile_env == "AWS_PROFILE_S3":
        ak = os.getenv("AWS_ACCESS_KEY_ID_S3") or S3_AWS_ACCESS_KEY_ID
        sk = os.getenv("AWS_SECRET_ACCESS_KEY_S3") or S3_AWS_SECRET_ACCESS_KEY
        st = os.getenv("AWS_SESSION_TOKEN_S3") or S3_AWS_SESSION_TOKEN
        return ak.strip(), sk.strip(), st.strip()

    if profile_env == "AWS_PROFILE_BEDROCK":
        ak = os.getenv("AWS_ACCESS_KEY_ID_BEDROCK") or BEDROCK_AWS_ACCESS_KEY_ID
        sk = os.getenv("AWS_SECRET_ACCESS_KEY_BEDROCK") or BEDROCK_AWS_SECRET_ACCESS_KEY
        st = os.getenv("AWS_SESSION_TOKEN_BEDROCK") or BEDROCK_AWS_SESSION_TOKEN
        return ak.strip(), sk.strip(), st.strip()

    return "", "", ""


def _make_session(region: str, profile_env: str, role_arn_env: str, session_name: str) -> boto3.Session:
    ak, sk, st = _pick_static_creds_for(profile_env)
    if ak and sk:
        return boto3.Session(
            aws_access_key_id=ak,
            aws_secret_access_key=sk,
            aws_session_token=(st or None),
            region_name=region,
        )

    profile = (os.getenv(profile_env) or "").strip()
    base = boto3.Session(profile_name=profile, region_name=region) if profile else boto3.Session(region_name=region)

    role_arn = (os.getenv(role_arn_env) or "").strip()
    if not role_arn:
        return base

    sts = base.client("sts", region_name=region)
    resp = sts.assume_role(RoleArn=role_arn, RoleSessionName=session_name)
    c = resp["Credentials"]
    return boto3.Session(
        aws_access_key_id=c["AccessKeyId"],
        aws_secret_access_key=c["SecretAccessKey"],
        aws_session_token=c["SessionToken"],
        region_name=region,
    )


def _scope_dir_from_scope_input(scope: str) -> str:
    s = (scope or "").strip()
    sc = s.lower()
    if sc in {"ultimate parent", "ultimate_parent"}:
        return "Ultimate Parent"
    if sc in {"corporate family", "corporate_family"}:
        return "Corporate Family"
    # else treat as country folder like "US"
    return (s.upper() or "COUNTRY")


@dataclass
class RagChunk:
    rank: int
    score: float
    text: str
    metadata: Dict[str, Any]


class RagSearchService:
    """
    Reads FAISS from:
      s3://<bucket>/<base_prefix>/<category>/<ID>/<scope_dir>/
    Where ID is:
      - capid (for country scope) OR
      - group_id (for Ultimate Parent / Corporate Family)
    """

    def __init__(
        self,
        faiss_index_dir: str,  # s3://bucket/prefix
        bedrock_region: str = "us-east-1",
        embedding_model_id: Optional[str] = None,
        default_top_k: int = 8,
        default_category: str = "finance",
        mmr_fetch_k: Optional[int] = None,
        mmr_lambda_mult: float = 0.5,
        faiss_cache_dir: Optional[str] = None,
        **_ignored_kwargs,
    ):
        load_dotenv()

        faiss_index_dir = str(faiss_index_dir or "").strip()
        if not faiss_index_dir.lower().startswith("s3://"):
            raise ValueError(f"FAISS_INDEX_DIR must be s3://bucket/path, got: {faiss_index_dir!r}")

        self.bedrock_region = bedrock_region
        self.bucket, self.base_prefix = _parse_s3_uri(faiss_index_dir.rstrip("/"))
        self.base_prefix = self.base_prefix.rstrip("/")

        self.embedding_model_id = embedding_model_id or os.getenv(
            "BEDROCK_EMBEDDING_MODEL",
            "amazon.titan-embed-text-v1",
        )

        self.default_top_k = int(default_top_k)
        self.default_category = (default_category or "finance").strip().lower()
        if self.default_category not in {"finance", "legal"}:
            self.default_category = "finance"

        self.mmr_fetch_k = int(mmr_fetch_k) if mmr_fetch_k is not None else max(self.default_top_k * 5, 25)
        self.mmr_lambda_mult = float(mmr_lambda_mult)

        self.faiss_cache_dir = (faiss_cache_dir or os.getenv("FAISS_INDEX_DIR_LOCAL") or "/tmp/faiss_indices").strip()
        if not self.faiss_cache_dir:
            self.faiss_cache_dir = "/tmp/faiss_indices"

        # S3 session
        self._s3_session = _make_session(
            region=self.bedrock_region,
            profile_env="AWS_PROFILE_S3",
            role_arn_env="AWS_ROLE_ARN_S3",
            session_name="rag-s3",
        )
        self._s3 = self._s3_session.client("s3", region_name=self.bedrock_region)

        # Bedrock session
        self._br_session = _make_session(
            region=self.bedrock_region,
            profile_env="AWS_PROFILE_BEDROCK",
            role_arn_env="AWS_ROLE_ARN_BEDROCK",
            session_name="rag-bedrock",
        )
        self._bedrock_runtime = self._br_session.client("bedrock-runtime", region_name=self.bedrock_region)

        self._embeddings = None

    def _list_keys(self, prefix: str) -> List[str]:
        prefix = prefix.rstrip("/") + "/"
        paginator = self._s3.get_paginator("list_objects_v2")
        out: List[str] = []
        for page in paginator.paginate(Bucket=self.bucket, Prefix=prefix):
            for obj in page.get("Contents", []) or []:
                k = obj.get("Key") or ""
                if k and not k.endswith("/"):
                    out.append(k)
        return out

    def _download(self, key: str, dest: Path) -> None:
        dest.parent.mkdir(parents=True, exist_ok=True)
        self._s3.download_file(self.bucket, key, str(dest))

    def _try_download_manifest(self, folder_prefix: str, local_folder: Path) -> Optional[Dict[str, Any]]:
        folder_prefix = folder_prefix.rstrip("/") + "/"
        manifest_key = folder_prefix + "manifest.json"
        try:
            self._download(manifest_key, local_folder / "manifest.json")
            data = (local_folder / "manifest.json").read_text(encoding="utf-8", errors="replace")
            return json.loads(data)
        except Exception:
            return None

    def _emb(self):
        if self._embeddings is not None:
            return self._embeddings
        self._embeddings = BedrockEmbeddings(model_id=self.embedding_model_id, client=self._bedrock_runtime)
        return self._embeddings

    def _pick_faiss_files_in_folder(self, folder_prefix: str) -> tuple[str, str]:
        folder_prefix = folder_prefix.rstrip("/") + "/"
        keys = self._list_keys(folder_prefix)

        faiss_candidates = [k for k in keys if k.lower().endswith(".faiss")]
        pkl_candidates = [k for k in keys if k.lower().endswith(".pkl")]

        if not faiss_candidates or not pkl_candidates:
            raise FileNotFoundError(f"Could not find both .faiss and .pkl under s3://{self.bucket}/{folder_prefix}")

        return faiss_candidates[0], pkl_candidates[0]

    def _load_faiss_store(self, folder: Path):
        try:
            return FAISS.load_local(str(folder), self._emb(), allow_dangerous_deserialization=True)
        except TypeError:
            return FAISS.load_local(str(folder), self._emb())

    def _json_sanitize(self, obj: Any) -> Any:
        if obj is None:
            return None
        if isinstance(obj, (str, int, float, bool)):
            return obj
        if isinstance(obj, Path):
            return str(obj)
        if isinstance(obj, dict):
            return {str(k): self._json_sanitize(v) for k, v in obj.items()}
        if isinstance(obj, (list, tuple, set)):
            return [self._json_sanitize(v) for v in obj]
        return str(obj)

    def retrieve_chunks_structured(
        self,
        query: str,
        *,
        capid: Optional[str] = None,
        group_id: Optional[str] = None,
        scope: str,
        category: Optional[str] = "finance",
        top_k: Optional[int] = None,
        include_manifest: bool = False,
    ) -> Dict[str, Any]:
        q = (query or "").strip()
        if not q:
            raise ValueError("query is required")

        cap = (capid or "").strip()
        gid = (group_id or "").strip()

        if bool(cap) == bool(gid):
            raise ValueError("Provide exactly one of capid OR group_id")

        scp = (scope or "").strip()
        if not scp:
            raise ValueError("scope is required (US / Ultimate Parent / Corporate Family)")

        cat = (category or self.default_category).strip().lower()
        if cat not in {"finance", "legal"}:
            cat = self.default_category

        k = int(top_k) if top_k else self.default_top_k

        id_used = cap or gid
        id_type = "capid" if cap else "group_id"
        scope_dir = _scope_dir_from_scope_input(scp)

        folder_prefix = _join_key(self.base_prefix, cat, id_used, scope_dir)
        faiss_key, pkl_key = self._pick_faiss_files_in_folder(folder_prefix)

        local_folder = Path(self.faiss_cache_dir) / self.base_prefix / cat / id_used / scope_dir
        self._download(faiss_key, local_folder / Path(faiss_key).name)
        self._download(pkl_key, local_folder / Path(pkl_key).name)

        store = self._load_faiss_store(local_folder)

        mmr_docs = store.max_marginal_relevance_search(
            q, k=k, fetch_k=self.mmr_fetch_k, lambda_mult=self.mmr_lambda_mult
        )
        scored = store.similarity_search_with_score(q, k=self.mmr_fetch_k)

        def _doc_key(d) -> str:
            md = getattr(d, "metadata", {}) or {}
            md_items = sorted((str(k2), str(v2)) for k2, v2 in md.items())
            return (getattr(d, "page_content", "") or "") + "||" + "||".join([f"{k2}={v2}" for k2, v2 in md_items])

        score_map: Dict[str, float] = {}
        for d, s in scored:
            key2 = _doc_key(d)
            if key2 not in score_map or float(s) < score_map[key2]:
                score_map[key2] = float(s)

        merged: List[RagChunk] = []
        for d in mmr_docs:
            text = (d.page_content or "").strip()
            md = dict(d.metadata or {})
            md.setdefault("_index_folder", str(local_folder))
            sc = score_map.get(_doc_key(d), 0.0)
            merged.append(RagChunk(rank=0, score=float(sc), text=text, metadata=md))

        merged.sort(key=lambda x: x.score)

        manifest_payload: Optional[Dict[str, Any]] = None
        if include_manifest:
            manifest_payload = self._try_download_manifest(folder_prefix, local_folder)

        return {
            "top_chunks": [{"text": ch.text, "metadata": self._json_sanitize(ch.metadata)} for ch in merged[:k]],
            "id_used": id_used,
            "id_type": id_type,
            "scope_dir": scope_dir,
            "category": cat,
            "manifest": manifest_payload,
        }
